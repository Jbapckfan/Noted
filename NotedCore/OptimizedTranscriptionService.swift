import Foundation
import WhisperKit
import AVFoundation
import Accelerate

/// Optimized transcription service with free performance improvements
@MainActor
final class OptimizedTranscriptionService: ObservableObject {
    static let shared = OptimizedTranscriptionService()

    @Published var isReady = false
    @Published var isProcessing = false
    @Published var transcriptionText = ""
    @Published var confidence: Float = 0.0
    @Published var processingSpeed = "0ms"

    // MARK: - Performance Optimizations
    private var whisperKit: WhisperKit?
    private var audioBuffer: [Float] = []
    private var lastTranscribedText = ""
    private var silenceFrames = 0

    // Optimized settings
    private let minBufferSize = 16000  // 1 second at 16kHz (reduced from 1.5s)
    private let maxBufferSize = 48000  // 3 seconds max to prevent memory buildup
    private let silenceThreshold: Float = 0.01
    private let minSilenceFrames = 8000  // 0.5 seconds of silence

    // Voice Activity Detection (VAD)
    private var voiceActivityLevel: Float = 0
    private let vadThreshold: Float = 0.02
    private var isVoiceActive = false

    // Smart caching
    private var transcriptionCache: [String: String] = [:]
    private let maxCacheSize = 50

    // Audio preprocessing
    private let noiseGate: Float = 0.005
    private var previousFrame: [Float] = []

    // Performance metrics
    private var lastProcessTime = Date()
    private var averageProcessingTime: Double = 0
    private var processCount = 0

    private init() {
        print("ðŸš€ OptimizedTranscriptionService initializing...")
        Task {
            await initializeOptimizedWhisper()
        }
    }

    // MARK: - Optimized Initialization
    private func initializeOptimizedWhisper() async {
        do {
            // Use tiny model for maximum speed with acceptable quality
            // tiny.en is 5-10x faster than base with 80% of the quality
            whisperKit = try await WhisperKit(
                model: "openai_whisper-tiny.en",  // Fastest model
                modelRepo: "argmaxinc/whisperkit-coreml",
                verbose: false,
                logLevel: .error,
                prewarm: true,  // Critical for speed
                load: true,
                download: true
            )

            // Configure for speed
            // Note: WhisperKit handles audio processing internally

            print("âœ… Optimized WhisperKit loaded (tiny.en model)")
            isReady = true

        } catch {
            print("âŒ Failed to load optimized WhisperKit: \(error)")
            // Fallback to defaults
            whisperKit = try? await WhisperKit()
            isReady = whisperKit != nil
        }
    }

    // MARK: - Voice Activity Detection (VAD)
    private func detectVoiceActivity(in samples: [Float]) -> Bool {
        // Calculate RMS energy
        var rms: Float = 0
        vDSP_rmsqv(samples, 1, &rms, vDSP_Length(samples.count))

        // Update voice activity level with smoothing
        voiceActivityLevel = (voiceActivityLevel * 0.7) + (rms * 0.3)

        // Check if voice is active
        let wasActive = isVoiceActive
        isVoiceActive = voiceActivityLevel > vadThreshold

        // Log state changes
        if wasActive != isVoiceActive {
            print(isVoiceActive ? "ðŸŽ¤ Voice detected" : "ðŸ”‡ Silence detected")
        }

        return isVoiceActive
    }

    // MARK: - Audio Preprocessing for Quality
    private func preprocessAudio(_ samples: [Float]) -> [Float] {
        var processed = samples

        // 1. Apply noise gate to remove low-level noise
        vDSP_vthres(
            processed, 1,
            [noiseGate],
            &processed, 1,
            vDSP_Length(samples.count)
        )

        // 2. Apply simple high-pass filter to remove DC offset and low-frequency noise
        if !previousFrame.isEmpty && previousFrame.count == processed.count {
            var filtered = [Float](repeating: 0, count: processed.count)
            // Simple first-order high-pass: y[n] = 0.95 * (y[n-1] + x[n] - x[n-1])
            let alpha: Float = 0.95
            for i in 0..<processed.count {
                if i > 0 {
                    filtered[i] = alpha * (filtered[i-1] + processed[i] - previousFrame[i])
                } else {
                    filtered[i] = processed[i]
                }
            }
            processed = filtered
        }
        previousFrame = processed

        // 3. Normalize audio level for consistent volume
        var maxValue: Float = 0
        vDSP_maxv(processed, 1, &maxValue, vDSP_Length(processed.count))

        if maxValue > 0.1 {  // Only normalize if there's significant audio
            var scale = 0.8 / maxValue  // Target 80% of maximum
            vDSP_vsmul(processed, 1, &scale, &processed, 1, vDSP_Length(processed.count))
        }

        return processed
    }

    // MARK: - Smart Chunking Strategy
    private func shouldProcessBuffer() -> Bool {
        // Process if:
        // 1. Buffer has minimum data and voice was detected
        // 2. Buffer is getting too large (prevent memory issues)
        // 3. Silence detected after speech (end of utterance)

        if audioBuffer.count >= maxBufferSize {
            print("âš¡ Force processing - buffer full")
            return true
        }

        if audioBuffer.count >= minBufferSize {
            if isVoiceActive {
                print("ðŸŽ¯ Processing - voice active with sufficient data")
                return true
            }

            if silenceFrames > minSilenceFrames && !audioBuffer.isEmpty {
                print("ðŸ”š Processing - end of utterance detected")
                return true
            }
        }

        return false
    }

    // MARK: - Optimized Parallel Audio Processing
    func processAudioOptimized(_ samples: [Float]) async {
        let startTime = Date()

        // Skip if not ready
        guard isReady, let whisperKit = whisperKit else { return }

        // Process audio in parallel using dedicated queue
        await withTaskGroup(of: Void.self) { group in
            // Parallel task 1: Voice activity detection
            group.addTask { [weak self] in
                guard let self = self else { return }
                await MainActor.run {
                    let processed = self.preprocessAudio(samples)
                    let hasVoice = self.detectVoiceActivity(in: processed)

                    if hasVoice {
                        self.silenceFrames = 0
                        self.audioBuffer.append(contentsOf: processed)
                    } else {
                        self.silenceFrames += samples.count
                        if !self.audioBuffer.isEmpty {
                            self.audioBuffer.append(contentsOf: processed)
                        }
                    }
                }
            }
        }

        // Preprocess audio for better quality
        let processed = preprocessAudio(samples)

        // Check for voice activity
        let hasVoice = detectVoiceActivity(in: processed)

        if hasVoice {
            // Reset silence counter when voice detected
            silenceFrames = 0
            // Add to buffer
            audioBuffer.append(contentsOf: processed)
        } else {
            // Count silence frames
            silenceFrames += samples.count

            // Don't add silence to buffer unless we're already recording
            if !audioBuffer.isEmpty {
                audioBuffer.append(contentsOf: processed)
            }
        }

        // Check if we should process
        if shouldProcessBuffer() && !isProcessing {
            isProcessing = true

            // Extract buffer for processing
            let processingBuffer = audioBuffer
            audioBuffer.removeAll()  // Clear immediately to not miss new audio

            // Check cache first
            let bufferHash = calculateHash(for: processingBuffer)
            if let cached = transcriptionCache[bufferHash] {
                print("âš¡ Cache hit - instant result!")
                updateTranscription(cached, confidence: 0.95)
                isProcessing = false
                return
            }

            // Process in background
            Task.detached { [weak self] in
                do {
                    // Use streaming mode for lower latency
                    let options = DecodingOptions(
                        task: .transcribe,
                        language: "en",
                        temperature: 0.0,  // Deterministic for consistency
                        temperatureFallbackCount: 0,  // Don't retry - speed is key
                        sampleLength: 224,  // Optimal chunk size
                        topK: 3,  // Limit beam search for speed
                        usePrefillPrompt: false,
                        usePrefillCache: true,
                        skipSpecialTokens: true,
                        withoutTimestamps: true  // Skip timestamps for speed
                    )

                    let results = try await whisperKit.transcribe(
                        audioArray: processingBuffer,
                        decodeOptions: options
                    )

                    if !results.isEmpty {
                        let text = results.map { $0.text }.joined(separator: " ")
                        let cleaned = text.trimmingCharacters(in: .whitespacesAndNewlines)

                        await MainActor.run { [weak self] in
                            guard let self = self else { return }

                            // Cache the result
                            self.transcriptionCache[bufferHash] = cleaned
                            if self.transcriptionCache.count > self.maxCacheSize {
                                // Remove oldest entries
                                self.transcriptionCache.removeAll()
                            }

                            // Update transcription
                            self.updateTranscription(cleaned, confidence: 0.85)

                            // Update performance metrics
                            let processingTime = Date().timeIntervalSince(startTime) * 1000
                            self.updatePerformanceMetrics(processingTime)
                        }
                    }
                } catch {
                    print("âŒ Transcription error: \(error)")
                }

                await MainActor.run { [weak self] in
                    self?.isProcessing = false
                }
            }
        }
    }

    // MARK: - Helper Methods
    private func calculateHash(for buffer: [Float]) -> String {
        // Simple hash for cache key
        let sum = buffer.reduce(0, +)
        let count = buffer.count
        return "\(count)_\(sum)"
    }

    private func updateTranscription(_ text: String, confidence: Float) {
        // Skip if identical to last
        if text == lastTranscribedText {
            return
        }

        lastTranscribedText = text
        self.confidence = confidence

        // Append with proper spacing
        if !transcriptionText.isEmpty && !text.isEmpty {
            transcriptionText += " "
        }
        transcriptionText += text

        print("ðŸ“ Transcribed: \(text) (confidence: \(confidence))")
    }

    private func updatePerformanceMetrics(_ processingTime: Double) {
        processCount += 1
        averageProcessingTime = ((averageProcessingTime * Double(processCount - 1)) + processingTime) / Double(processCount)
        processingSpeed = String(format: "%.0fms", averageProcessingTime)
        print("âš¡ Processing time: \(processingSpeed) (current: \(String(format: "%.0fms", processingTime)))")
    }

    // MARK: - Public Methods
    func reset() {
        transcriptionText = ""
        audioBuffer.removeAll()
        lastTranscribedText = ""
        silenceFrames = 0
        isVoiceActive = false
        voiceActivityLevel = 0
        previousFrame.removeAll()
        transcriptionCache.removeAll()
    }

    func getOptimizationStats() -> String {
        """
        ðŸŽ¯ Optimization Stats:
        â€¢ Model: Tiny (5-10x faster)
        â€¢ VAD Active: \(isVoiceActive ? "Yes" : "No")
        â€¢ Cache Hits: \(transcriptionCache.count)/\(maxCacheSize)
        â€¢ Avg Speed: \(processingSpeed)
        â€¢ Buffer: \(audioBuffer.count)/\(maxBufferSize)
        """
    }
}

// MARK: - Decoding Options Extension
extension DecodingOptions {
    /// Optimized options for real-time transcription
    static var realtime: DecodingOptions {
        DecodingOptions(
            task: .transcribe,
            language: "en",
            temperature: 0.0,
            temperatureFallbackCount: 0,
            sampleLength: 224,
            topK: 3,
            usePrefillPrompt: false,
            usePrefillCache: true,
            skipSpecialTokens: true,
            withoutTimestamps: true
        )
    }
}